{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pFJn-RZIC0cm"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","np.random.seed(0)\n","df_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/polynomial_train.csv\",index_col = 0)\n","\n","def sigmoid(z):\n","    return 1/(1+np.exp(-z))\n","\n","def sigmoid_derivative (x):\n","    return sigmoid(x)*(1-sigmoid(x))\n","\n","def R2(out,y):\n","    return 1 - (np.sum((out-y)**2))/(np.sum((y - np.mean(y))**2))\n","\n","\n","class Layer():\n","    def __init__(self,n_inputs,n_neurons):\n","        self.weights = np.random.randn(n_inputs,n_neurons)\n","        self.bias = np.random.randn(1,n_neurons)\n","    def forward(self,inputs):\n","        self.outputs = inputs @ self.weights + self.bias\n","        \n","    def backward(self,error,weights):\n","        self.error = ( error @ np.transpose(weights) ) * sigmoid_derivative(self.outputs)\n","\n","    def set_error(self,error):\n","        self.error = error\n","\n","    def fill():\n","        pass\n"," \n","def forward_propagate(x,layers,act):\n","    \n","    n = len(layers)-1\n","    for i in range(n):\n","        \n","        if i == 0 :\n","            layers[0].forward(x)\n","            act[0] = sigmoid(layers[0].outputs)\n","        else:\n","            layers[i].forward(act[i-1])\n","            act[i] = sigmoid(layers[i].outputs)\n","\n","    layers[n].forward(act[n-1])\n","    act[n] = (layers[n].outputs)\n","\n","    return layers,act\n","\n","def backward_propagate(x,y,learning_rate,layers,act):\n","    size = act[-1].shape[0]\n","    n = len(layers) -1\n","    error = -(act[-1]-y)\n","\n","    for i in range(n,0,-1):\n","        if i == (n):\n","            layers[i].set_error(error)\n","            Jw = np.array(act[i-1]).T @ layers[i].error \n","            Jb = np.sum(layers[i].error,axis = 0)\n","\n","        else :\n","            layers[i].backward(layers[i+1].error,layers[i+1].weights)\n","            Jw = np.array(act[i-1]).T @ layers[i].error\n","            Jb = np.sum(layers[i].error,axis = 0)\n","\n","        layers[i].weights += learning_rate/size*Jw\n","        layers[i].bias += learning_rate/size*Jb\n","\n","    layers[0].backward(layers[1].error,layers[1].weights)\n","    Jw = np.array(x).T @ layers[0].error\n","    Jb = np.sum(layers[0].error,axis = 0)\n","\n","    layers[0].weights += learning_rate/size*Jw\n","    layers[0].bias += learning_rate/size*Jb\n","\n","    return layers\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"U6wR0NsFDEgc","executionInfo":{"status":"ok","timestamp":1680011612015,"user_tz":-330,"elapsed":795,"user":{"displayName":"Alok Raj","userId":"11236244298665653253"}}},"outputs":[],"source":["train_data = df_train.iloc[:45000,:-1].values\n","test_data = df_train.iloc[45000:,:-1].values\n","label_train = df_train.iloc[:45000,-1].to_numpy()\n","label_test = df_train.iloc[45000:,-1].to_numpy()\n","\n","x = (train_data - np.mean(train_data))/np.std(train_data)\n","x_test = (test_data - np.mean(train_data))/np.std(train_data)\n","y = (label_train - np.mean(label_train))/np.std(label_train)\n","y_test = (label_test - np.mean(label_train))/np.std(label_train)\n","\n","y = y.reshape([label_train.shape[0],1])\n","y_test = y_test.reshape([label_test.shape[0],1])\n","\n","n = 2 # no of hidden layers\n","m = 56 # no of neurons\n","layers , act = [1]*(n+1),[1]*(n+1)\n","\n","for i in range(n):\n","    if i == 0 :\n","        layers[0] = Layer(3,m)\n","        layers[0].forward(x)\n","        act[0] = sigmoid(layers[0].outputs)\n","    else:\n","        layers[i] = Layer(m,m)\n","        layers[i].forward(act[i-1])\n","        act[i] = sigmoid(layers[i].outputs)\n","layers[n] = Layer(m,1)\n","layers[n].forward(act[n-1])\n","act[n] = (layers[n].outputs)\n","\n","layers[0].weights = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw1.npy\")\n","layers[0].bias = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb1.npy\")\n","layers[1].weights = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw2.npy\")\n","layers[1].bias = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb2.npy\")\n","layers[2].weights = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw3.npy\")\n","layers[2].bias = np.load(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb3.npy\")\n","\n"]},{"cell_type":"code","source":["learning_rate=0.01\n","n_iterations = 30\n","start = 0\n","end = x.shape[0]\n","step = x.shape[0]//10\n","\n","for i in range(n_iterations):\n","    for k in range(start,end,step):\n","\n","        layers,act = forward_propagate(x[k:k+step,:],layers,act)\n","        layers = backward_propagate(x[k:k+step,:],y[k:k+step,0].reshape([step,1]),learning_rate,layers,act)\n","        layers,act = forward_propagate(x[k:k+step,:],layers,act)\n","\n","        loss = np.mean((act[-1] - y[k:k+step,0].reshape([step,1]))**2)\n","        if ((i+1) % 10 == 0):\n","            print(\"After {} iterations : \".format(i+1))\n","            print(\"loss = \",loss)\n","            layers_test , act_test = forward_propagate(x_test,layers,act)\n","            score = R2(act_test[-1],y_test)\n","            print(score*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cj6bwerJrq7","executionInfo":{"status":"ok","timestamp":1680011638449,"user_tz":-330,"elapsed":22470,"user":{"displayName":"Alok Raj","userId":"11236244298665653253"}},"outputId":"62ab58e3-cc0b-4a3d-e5b5-b670d1643a20"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["After 10 iterations : \n","loss =  0.00015788673405420806\n","99.94174482375942\n","After 10 iterations : \n","loss =  0.0004183937069921802\n","99.9422425572986\n","After 10 iterations : \n","loss =  0.0005731404941801605\n","99.94243140479412\n","After 10 iterations : \n","loss =  0.00019901376531515934\n","99.94257759179335\n","After 10 iterations : \n","loss =  0.0005222090006915669\n","99.94268447549034\n","After 10 iterations : \n","loss =  0.00026876126090838475\n","99.9426199492613\n","After 10 iterations : \n","loss =  0.016703634602640204\n","99.94105718344937\n","After 10 iterations : \n","loss =  0.0008218922701774235\n","99.9407927892289\n","After 10 iterations : \n","loss =  0.000267871138151154\n","99.9408873232942\n","After 10 iterations : \n","loss =  0.0006482094158221872\n","99.94179059536172\n","After 20 iterations : \n","loss =  0.00015788862939173794\n","99.94175034636643\n","After 20 iterations : \n","loss =  0.00041842282287712587\n","99.94224797106523\n","After 20 iterations : \n","loss =  0.0005731345722543544\n","99.94243685097699\n","After 20 iterations : \n","loss =  0.00019895370489688677\n","99.94258289945536\n","After 20 iterations : \n","loss =  0.0005222645641074803\n","99.94269004203548\n","After 20 iterations : \n","loss =  0.0002686620359630705\n","99.94262556817539\n","After 20 iterations : \n","loss =  0.016700179352001753\n","99.94106279601536\n","After 20 iterations : \n","loss =  0.0008219434786613189\n","99.94079898280702\n","After 20 iterations : \n","loss =  0.00026777339128659125\n","99.94089347207324\n","After 20 iterations : \n","loss =  0.0006481370281812209\n","99.9417963924762\n","After 30 iterations : \n","loss =  0.00015786922263789043\n","99.94175754831728\n","After 30 iterations : \n","loss =  0.0004184064942143417\n","99.94225509741325\n","After 30 iterations : \n","loss =  0.0005730783396936408\n","99.94244396648403\n","After 30 iterations : \n","loss =  0.0001989094994038905\n","99.94258994041411\n","After 30 iterations : \n","loss =  0.0005222173601878773\n","99.94269713320308\n","After 30 iterations : \n","loss =  0.0002685966497196666\n","99.94263267949033\n","After 30 iterations : \n","loss =  0.016697018160424033\n","99.94106998185883\n","After 30 iterations : \n","loss =  0.0008218662686957721\n","99.94080639045367\n","After 30 iterations : \n","loss =  0.00026768712925762854\n","99.94090087757735\n","After 30 iterations : \n","loss =  0.0006480493077451378\n","99.94180358426972\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzJMYHe3NgcS"},"outputs":[],"source":["np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw1.npy\",layers[0].weights)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb1.npy\",layers[0].bias)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw2.npy\",layers[1].weights)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb2.npy\",layers[1].bias)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpw3.npy\",layers[2].weights)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnpb3.npy\",layers[2].bias)\n"]},{"cell_type":"code","source":["df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/polynomial_test_data.csv\")\n","X_test = df_test.iloc[:,1:].values\n","ids = df_test.iloc[:,0].values\n","\n","Test_data = (X_test - np.mean(train_data))/np.std(train_data)\n","layers_test,act_test = forward_propagate(Test_data,layers,act)\n","Y_pred = layers_test[-1].outputs\n","Y_res = Y_pred * np.std(label_train,axis = 0) + np.mean(label_train,axis = 0)\n","\n","res = pd.DataFrame([ids,Y_res],index = [\"Ids\",\"Prediction\"]).T\n","print(res)\n","res.to_csv(\"/content/drive/MyDrive/Colab Notebooks/ML Bootcamp data/Neural_Networks_Poly/nnp_result.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnFs0SmOVtte","executionInfo":{"status":"ok","timestamp":1680007951364,"user_tz":-330,"elapsed":3181,"user":{"displayName":"Alok Raj","userId":"11236244298665653253"}},"outputId":"171d9488-f705-43a3-c41b-1ab77fdcb105"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         Ids             Prediction\n","0      78886    [1685.377375445867]\n","1      35987    [261700.8799403772]\n","2      63576   [3337.9071319623654]\n","3      86537  [-2115210.2051618095]\n","4      45235  [-37546.270709370605]\n","...      ...                    ...\n","19995  42763  [-14718.868539003783]\n","19996  52748   [-5277.835828283631]\n","19997  42159   [-8328.553595482274]\n","19998  22095  [-1704.4829518548722]\n","19999  80712   [-81518.75964029648]\n","\n","[20000 rows x 2 columns]\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1QM4BXhpLSYwbuIrNBME8glZz-o7pfeKk","authorship_tag":"ABX9TyM8T0p1RvKCBz0udp+fUXto"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}